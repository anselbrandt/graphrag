{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folder does not exist locally, attempting to use huggingface hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795ab6d599dc473e9e9872dfd14f9671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansel/ai/graphrag/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import time\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "\n",
    "logging.getLogger(\"httpx\").setLevel(logging.ERROR)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(message)s\",\n",
    "    handlers=[logging.FileHandler(\"logs.txt\"), stream_handler],\n",
    ")\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions.sentence_transformer_embedding_function import (\n",
    "    SentenceTransformerEmbeddingFunction,\n",
    ")\n",
    "from gliner import GLiNER\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from chunking_utils import get_chunks\n",
    "from llm_utils import ask_llm\n",
    "from metadata_utils import get_meta\n",
    "from nlp_utils import get_entities, get_tags, get_relevant_chunks\n",
    "from transcript_utils import srt_to_text\n",
    "\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    start: int\n",
    "    end: int\n",
    "    text: str\n",
    "    label: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_base\", max_length=768)\n",
    "\n",
    "LLM_MODEL = \"qwen2.5:14b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "chromadb_dir = Path(\"chromadb\")\n",
    "chromadb_dir.mkdir(exist_ok=True)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=str(chromadb_dir))\n",
    "collection = chroma_client.get_or_create_collection(name=\"roderick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: rotl_107_summary\n",
      "Insert of existing embedding ID: rotl_107_summary\n",
      "Add of existing embedding ID: rotl_107_0\n",
      "Add of existing embedding ID: rotl_107_1\n",
      "Add of existing embedding ID: rotl_107_2\n",
      "Add of existing embedding ID: rotl_107_3\n",
      "Add of existing embedding ID: rotl_107_4\n",
      "Add of existing embedding ID: rotl_107_5\n",
      "Add of existing embedding ID: rotl_107_6\n",
      "Add of existing embedding ID: rotl_107_7\n",
      "Add of existing embedding ID: rotl_107_8\n",
      "Add of existing embedding ID: rotl_107_9\n",
      "Add of existing embedding ID: rotl_107_10\n",
      "Add of existing embedding ID: rotl_107_11\n",
      "Add of existing embedding ID: rotl_107_12\n",
      "Add of existing embedding ID: rotl_107_13\n",
      "Add of existing embedding ID: rotl_107_14\n",
      "Add of existing embedding ID: rotl_107_15\n",
      "Add of existing embedding ID: rotl_107_16\n",
      "Add of existing embedding ID: rotl_107_17\n",
      "Add of existing embedding ID: rotl_107_18\n",
      "Add of existing embedding ID: rotl_107_19\n",
      "Add of existing embedding ID: rotl_107_20\n",
      "Add of existing embedding ID: rotl_107_21\n",
      "Add of existing embedding ID: rotl_107_22\n",
      "Add of existing embedding ID: rotl_107_23\n",
      "Add of existing embedding ID: rotl_107_24\n",
      "Add of existing embedding ID: rotl_107_25\n",
      "Add of existing embedding ID: rotl_107_26\n",
      "Add of existing embedding ID: rotl_107_27\n",
      "Add of existing embedding ID: rotl_107_28\n",
      "Add of existing embedding ID: rotl_107_29\n",
      "Add of existing embedding ID: rotl_107_30\n",
      "Add of existing embedding ID: rotl_107_31\n",
      "Add of existing embedding ID: rotl_107_32\n",
      "Add of existing embedding ID: rotl_107_33\n",
      "Add of existing embedding ID: rotl_107_34\n",
      "Add of existing embedding ID: rotl_107_35\n",
      "Insert of existing embedding ID: rotl_107_0\n",
      "Insert of existing embedding ID: rotl_107_1\n",
      "Insert of existing embedding ID: rotl_107_2\n",
      "Insert of existing embedding ID: rotl_107_3\n",
      "Insert of existing embedding ID: rotl_107_4\n",
      "Insert of existing embedding ID: rotl_107_5\n",
      "Insert of existing embedding ID: rotl_107_6\n",
      "Insert of existing embedding ID: rotl_107_7\n",
      "Insert of existing embedding ID: rotl_107_8\n",
      "Insert of existing embedding ID: rotl_107_9\n",
      "Insert of existing embedding ID: rotl_107_10\n",
      "Insert of existing embedding ID: rotl_107_11\n",
      "Insert of existing embedding ID: rotl_107_12\n",
      "Insert of existing embedding ID: rotl_107_13\n",
      "Insert of existing embedding ID: rotl_107_14\n",
      "Insert of existing embedding ID: rotl_107_15\n",
      "Insert of existing embedding ID: rotl_107_16\n",
      "Insert of existing embedding ID: rotl_107_17\n",
      "Insert of existing embedding ID: rotl_107_18\n",
      "Insert of existing embedding ID: rotl_107_19\n",
      "Insert of existing embedding ID: rotl_107_20\n",
      "Insert of existing embedding ID: rotl_107_21\n",
      "Insert of existing embedding ID: rotl_107_22\n",
      "Insert of existing embedding ID: rotl_107_23\n",
      "Insert of existing embedding ID: rotl_107_24\n",
      "Insert of existing embedding ID: rotl_107_25\n",
      "Insert of existing embedding ID: rotl_107_26\n",
      "Insert of existing embedding ID: rotl_107_27\n",
      "Insert of existing embedding ID: rotl_107_28\n",
      "Insert of existing embedding ID: rotl_107_29\n",
      "Insert of existing embedding ID: rotl_107_30\n",
      "Insert of existing embedding ID: rotl_107_31\n",
      "Insert of existing embedding ID: rotl_107_32\n",
      "Insert of existing embedding ID: rotl_107_33\n",
      "Insert of existing embedding ID: rotl_107_34\n",
      "Insert of existing embedding ID: rotl_107_35\n",
      "rotl 107 entities generated 14.0s\n",
      "rotl 107 Mom 2.1s\n",
      "rotl 107 month ago 2.7s\n",
      "rotl 107 motor 3.5s\n",
      "rotl 107 motorized wheelchair 2.8s\n",
      "rotl 107 musician 2.6s\n",
      "rotl 107 nanny state 3.1s\n",
      "rotl 107 NASCAR 3.7s\n",
      "rotl 107 NASCAR racers 3.9s\n",
      "rotl 107 national brands 2.6s\n",
      "rotl 107 National Socialists 3.1s\n",
      "rotl 107 national stick fight 2.1s\n",
      "rotl 107 neighborhood stick fights 3.8s\n",
      "rotl 107 Nerds 3.3s\n",
      "rotl 107 Nike 4.0s\n",
      "rotl 107 nine eleven 1.9s\n",
      "rotl 107 nineteen seventies 2.3s\n",
      "rotl 107 nineteen seventy 1.6s\n",
      "rotl 107 nineties 4.1s\n",
      "rotl 107 Ninety minute 1.4s\n",
      "rotl 107 north face 3.1s\n",
      "rotl 107 Nutty professor 3.1s\n",
      "rotl 107 Obama 4.0s\n",
      "rotl 107 oboe dance music 2.9s\n",
      "rotl 107 oboe music 2.2s\n",
      "rotl 107 oceans 2.2s\n",
      "rotl 107 odor eater 2.8s\n",
      "rotl 107 office 6.9s\n",
      "rotl 107 office building 5.1s\n",
      "rotl 107 office space 3.3s\n",
      "rotl 107 old man 2.6s\n",
      "rotl 107 one year 2.1s\n",
      "rotl 107 onesie 4.0s\n",
      "rotl 107 onesies 4.0s\n",
      "rotl 107 online store 2.1s\n",
      "rotl 107 orange flight suit 1.8s\n",
      "rotl 107 overalls 1.8s\n",
      "rotl 107 paint store 2.3s\n",
      "rotl 107 painter 3.6s\n",
      "rotl 107 patches 2.2s\n",
      "rotl 107 people 5.6s\n",
      "rotl 107 Pepsi 4.4s\n",
      "rotl 107 phone 2.5s\n",
      "rotl 107 phone companies 2.4s\n",
      "rotl 107 pie plate 2.6s\n",
      "rotl 107 pimple-faced kid 2.4s\n",
      "rotl 107 polo pony 5.0s\n",
      "rotl 107 polyester pills 2.1s\n",
      "rotl 107 population 2.5s\n",
      "rotl 107 porn actress 2.7s\n",
      "rotl 107 pumpkin 2.9s\n",
      "rotl 107 PYT 2.3s\n",
      "rotl 107 Ralph Lauren 4.1s\n",
      "rotl 107 ralph loren 2.1s\n",
      "rotl 107 ramp 3.0s\n",
      "rotl 107 Rascal 2.0s\n",
      "rotl 107 Rascals 3.2s\n",
      "rotl 107 RC 1.8s\n",
      "rotl 107 record 3.6s\n",
      "rotl 107 rent-to-own furniture model 4.0s\n",
      "rotl 107 restaurant 5.1s\n",
      "rotl 107 restaurants 3.7s\n",
      "rotl 107 ribbons 2.9s\n",
      "rotl 107 Riley 3.2s\n",
      "rotl 107 Rob Florent 2.8s\n",
      "rotl 107 Roderick 3.2s\n",
      "rotl 107 Roderick Group 3.9s\n",
      "rotl 107 Roderick on the Line 3.5s\n",
      "rotl 107 Rolodex 3.7s\n",
      "rotl 107 Rorschach 3.1s\n",
      "rotl 107 Seattle 2.4s\n",
      "rotl 107 second day 3.2s\n",
      "rotl 107 Segway 2.2s\n",
      "rotl 107 Sergeant at Arms 2.8s\n",
      "rotl 107 seventies 3.5s\n",
      "rotl 107 shell oil 2.4s\n",
      "rotl 107 shirt 3.8s\n",
      "rotl 107 shoe balloon 5.2s\n",
      "rotl 107 shoes 4.2s\n",
      "rotl 107 side zip 2.0s\n",
      "rotl 107 slippers 3.1s\n",
      "rotl 107 sock 2.2s\n",
      "rotl 107 sole 2.3s\n",
      "rotl 107 Soviet Union 1.8s\n",
      "rotl 107 Spanish inquisition 3.0s\n",
      "rotl 107 sports jacket 3.0s\n",
      "rotl 107 sportswear logos 4.0s\n",
      "rotl 107 Squarespace 4.2s\n",
      "rotl 107 standing wheelchair 2.2s\n",
      "rotl 107 Star of David 1.5s\n",
      "rotl 107 startups 3.2s\n",
      "rotl 107 stick fight 3.5s\n",
      "rotl 107 store 3.6s\n",
      "rotl 107 stovepipe pants 2.5s\n",
      "rotl 107 stroke of midnight 4.0s\n",
      "rotl 107 students 1.8s\n",
      "rotl 107 Subway sandwich 2.0s\n",
      "rotl 107 suede 3.7s\n",
      "rotl 107 suit 4.1s\n"
     ]
    }
   ],
   "source": [
    "def exists(id):\n",
    "    results = collection.get(ids=[id])\n",
    "    return True if results[\"documents\"] and len(results[\"documents\"]) else False\n",
    "\n",
    "\n",
    "files = [\n",
    "    file for file in sorted(Path(\"../files/rotl\").iterdir()) if \".srt\" in file.name\n",
    "]\n",
    "\n",
    "last_file = \"106\"\n",
    "filtered_files = [file for file in files if float(get_meta(file)[1]) > float(last_file)]\n",
    "\n",
    "for file in filtered_files:\n",
    "    start_episode = time.time()\n",
    "\n",
    "    file_name, episode_number, episode_date, episode_title = get_meta(file)\n",
    "    transcript = srt_to_text(file)\n",
    "\n",
    "    summary_instructions = f\"Summarize this episode of Roderick on the Line\"\n",
    "    summary = ask_llm(\n",
    "        f\"{transcript}\\n\\n{summary_instructions}\", model=LLM_MODEL, tokens=500\n",
    "    )\n",
    "    summary_metadata = {\n",
    "        \"chunks\": \"\",\n",
    "        \"show\": \"Roderick on the Line\",\n",
    "        \"episode\": episode_number,\n",
    "        \"title\": episode_title,\n",
    "        \"subject\": f\"Roderick on the Line, episode {episode_number}, {episode_title}\",\n",
    "        \"category\": \"Summary\",\n",
    "        \"tags\": f\"Roderick on the Line, episode {episode_number}, {episode_title}\",\n",
    "    }\n",
    "    summary_id = f\"rotl_{episode_number}_summary\"\n",
    "    summary_doc = f\"Roderick on the Line\\n\\nEpisode {episode_number}\\n\\n{episode_title}\\n\\nSummary of Roderick on the Line, episode {episode_number}, {episode_title}, {episode_date}\\n\\n{summary}\"\n",
    "\n",
    "    collection.add(\n",
    "        documents=[summary_doc], metadatas=[summary_metadata], ids=[summary_id]\n",
    "    )\n",
    "\n",
    "    chunks = get_chunks(transcript)\n",
    "    metadatas = [\n",
    "        {\n",
    "            \"chunks\": str(i),\n",
    "            \"show\": \"Roderick on the Line\",\n",
    "            \"episode\": episode_number,\n",
    "            \"title\": episode_title,\n",
    "            \"subject\": \"\",\n",
    "            \"category\": \"\",\n",
    "            \"tags\": \"\",\n",
    "        }\n",
    "        for i in range(len(chunks))\n",
    "    ]\n",
    "    ids = [f\"rotl_{episode_number}_{str(i)}\" for i in range(len(chunks))]\n",
    "\n",
    "    collection.add(documents=chunks, metadatas=metadatas, ids=ids)\n",
    "\n",
    "    results = get_entities(chunks, model)\n",
    "\n",
    "    logging.info(\n",
    "        f\"rotl {episode_number} entities generated {(time.time() - start_episode):.1f}s\"\n",
    "    )\n",
    "    for entity, data in results.items():\n",
    "        id = f\"{entity}_rotl_{episode_number}\"\n",
    "        if not exists(id):\n",
    "            start_entity = time.time()\n",
    "            labels = data[\"labels\"]\n",
    "            indexes = data[\"indexes\"]\n",
    "            relevant_chunks = get_relevant_chunks(chunks, indexes)\n",
    "\n",
    "            context = \"\\n\".join(relevant_chunks)\n",
    "            question = f\"What do John and Merlin say about {entity}?\"\n",
    "            start_answer = time.time()\n",
    "            answer = ask_llm(f\"{context}\\n\\n{question}\", model=LLM_MODEL, tokens=500)\n",
    "\n",
    "            tags = get_tags(answer, model, stopwords=[\"john\", \"merlin\"])\n",
    "\n",
    "            doc = f\"{entity}\\n\\n{', '.join(labels)}\\n\\n{', '.join(tags)}\\n\\n{answer}\"\n",
    "\n",
    "            metadata = {\n",
    "                \"chunks\": \",\".join([str(i) for i in indexes]),\n",
    "                \"show\": \"Roderick on the Line\",\n",
    "                \"episode\": episode_number,\n",
    "                \"title\": episode_title,\n",
    "                \"subject\": entity,\n",
    "                \"category\": \",\".join(labels),\n",
    "                \"tags\": \",\".join(tags),\n",
    "            }\n",
    "\n",
    "            collection.add(documents=[doc], ids=[id], metadatas=[metadata])\n",
    "            logging.info(\n",
    "                f\"rotl {episode_number} {entity} {(time.time() - start_entity):.1f}s\"\n",
    "            )\n",
    "    td = timedelta(seconds=time.time() - start_episode)\n",
    "    formatted = f\"{td.seconds // 60}min {td.seconds % 60}s\"\n",
    "    logging.info(f\"rotl {episode_number} {episode_title} {formatted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided in your summary, Merlin attended a small liberal arts college in Sarasota, Florida. He describes this place as being very insular with around 520 students when he was there. The environment at his college seems quite unique and unconventional, allowing for behaviors such as walking barefoot on campus which would be unusual elsewhere. This period of his life appears to have been significant and transformative despite its tumultuous nature, typical of experiences in early adulthood.\n"
     ]
    }
   ],
   "source": [
    "query = \"Where did Merlin go to college?\"\n",
    "results = collection.query(query_texts=[query], n_results=10)\n",
    "\n",
    "docs = results[\"documents\"][0]\n",
    "\n",
    "context = \"\\n\".join(docs)\n",
    "\n",
    "answer = ask_llm(f\"{context}\\n\\n{query}\", model=LLM_MODEL, tokens=500)\n",
    "\n",
    "print(answer)\n",
    "\n",
    "with open(\"docs.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
