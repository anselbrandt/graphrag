{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f083232f6846d3970e2bb0bc1ccd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansel/ai/graphrag/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from gliner import GLiNER\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from chunking_utils import get_chunks\n",
    "from llm_utils import ask_llm\n",
    "from metadata_utils import get_meta\n",
    "from nlp_utils import get_entities, get_tags, get_relevant_chunks\n",
    "from transcript_utils import srt_to_text\n",
    "\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    start: int\n",
    "    end: int\n",
    "    text: str\n",
    "    label: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_base\", max_length=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the conversation, John mentions Eleanor as his old landlord's wife who didn't want the cats in the house. Specifically, when John describes the situation with the old man feeding the cats, he says:\n",
      "\"John: And she was like, no, it's crazy.\n",
      "John: There are cats everywhere.\"\n",
      "This indicates that Eleanor was against her husband continuing to feed the cats and eventually forbade him from doing so. When the cats left, the rats moved in, leading to a new problem for the old man who then started feeding the rats. This shows that Eleanor played a significant role in the changes that occurred after the cats were no longer fed.\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    file\n",
    "    for file in sorted(Path(\"../files/rotl\").iterdir())\n",
    "    if \".srt\" in file.name\n",
    "    if \"398\" in file.name\n",
    "]\n",
    "\n",
    "LLM_MODEL = \"qwen2.5:14b\"\n",
    "\n",
    "for file in files:\n",
    "    file_name, episode_number, episode_date, episode_title = get_meta(file)\n",
    "    transcript = srt_to_text(file)\n",
    "    chunks = get_chunks(transcript)\n",
    "    results = get_entities(chunks, model)\n",
    "\n",
    "    for entity, data in results.items():\n",
    "        if entity == \"Eleanor\":\n",
    "            labels = data[\"labels\"]\n",
    "            indexes = data[\"indexes\"]\n",
    "            relevant_chunks = get_relevant_chunks(chunks, indexes)\n",
    "\n",
    "            context = \"\\n\".join(relevant_chunks)\n",
    "            question = f\"What do John and Merlin say about {entity}?\"\n",
    "            answer = ask_llm(f\"{context}\\n\\n{question}\", model=LLM_MODEL, tokens=500)\n",
    "\n",
    "            tags = get_tags(answer, model, stopwords=[\"john\", \"merlin\"])\n",
    "\n",
    "            info = f\"{entity}\\n\\n{', '.join(labels)}\\n\\n{', '.join(tags)}\\n\\n{answer}\\n\\n{indexes}\"\n",
    "\n",
    "            id = f\"{entity}_rotl_{episode_number}\"\n",
    "            metadata = {\n",
    "                \"chunks\": indexes,\n",
    "                \"show\": \"Roderick on the Line\",\n",
    "                \"episode\": episode_number,\n",
    "                \"title\": episode_title,\n",
    "                \"subject\": entity,\n",
    "                \"category\": labels,\n",
    "                \"tags\": tags,\n",
    "            }\n",
    "\n",
    "            print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Alyeska\n",
    "\n",
    "Location\n",
    "\n",
    "Alaska, Alyeska, paper towels, ski resort\n",
    "\n",
    "Here's what John and Merlin say about Alyeska:\n",
    "* **Alyeska is the name of a ski resort where John grew up.**  He says it's a name you might want to give a dog or child, but not in Girdwood, Alaska. \n",
    "* **In Girdwood, many dogs are named Alyeska and many are named Max** (after Mount Max's Mountain). John finds this strange and doesn't understand the trend.\n",
    "* **John's cat is named Alyeska.** He says that if you named your dog Alyeska in Girdwood, they would bury you in a peat bog. \n",
    "Let me know if you have any other questions about their conversation!\n",
    "\n",
    "metadata: {\n",
    "            \"chunks\":[5, 6, 7],\n",
    "            \"show\":\"Roderick on the Line\",\n",
    "            \"episode\":\"389\",\n",
    "            \"title\":\"The New March\",\n",
    "            \"subject\":\"Alyeska\",\n",
    "            \"Category\":[\"Location\",\"Person\"]\n",
    "            \"tags\":[\n",
    "                    \"Alaska\", \"Alyeska\", \"Girdwood\", \"Max\"\n",
    "                    ]\n",
    "            }\n",
    "\n",
    "id: rotl_398_Alyeska\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
